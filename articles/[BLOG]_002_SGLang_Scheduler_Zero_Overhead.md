# SGLang è°ƒåº¦ç³»ç»Ÿï¼šä» KV Cache åˆ° Zero Overhead Scheduling

## ğŸ“Œ å…ƒæ•°æ®

- **æ¥æº**: https://zhuanlan.zhihu.com/p/1992587332189197731
- **ä½œè€…**: Chayenne Zhao (èµµæ™¨é˜³)
- **æœºæ„**: Qwen RL Infra Team
- **æ—¥æœŸ**: 2026-01-08
- **é˜…è¯»æ—¥æœŸ**: 2025-02-01
- **åˆ†ç±»**: `APP`
- **æ ‡ç­¾**: #SGLang #Scheduler #KVCache #OverlapScheduling #ZeroOverhead #InferenceOptimization

---

## ğŸ“– æ–‡ç« æ¦‚è¿°

è¿™ç¯‡æ–‡ç« æ·±å…¥è§£æäº† SGLang çš„è°ƒåº¦ç³»ç»Ÿï¼Œä» KV Cache ç®¡ç†åˆ° Zero Overhead Scheduling çš„å®Œæ•´æŠ€æœ¯æ ˆã€‚æ–‡ç« ç³»ç»Ÿæ€§åœ°ä»‹ç»äº† SGLang çš„æ ¸å¿ƒæ•°æ®ç»“æ„ã€è°ƒåº¦æµç¨‹ä»¥åŠå¦‚ä½•é€šè¿‡ CPU-GPU é‡å å®ç°é›¶å¼€é”€è°ƒåº¦ã€‚

**æ ¸å¿ƒä»·å€¼**ï¼šç†è§£æ¨ç†ç³»ç»Ÿçš„ä¸Šé™å–å†³äºå¯¹è°ƒåº¦å™¨å’Œ KV Cache ç®¡ç†çš„æ·±åˆ»è®¤çŸ¥ã€‚

---

## ğŸ¯ æ ¸å¿ƒå†…å®¹

### ä¸»è¦è§‚ç‚¹

1. **ä¸‰çº§ç¼“å­˜æ¶æ„**
   - **L1 - RadixCache (é€»è¾‘å±‚)**: ç»´æŠ¤ Token åºåˆ—ä¸ç‰©ç†åœ°å€çš„æ˜ å°„
   - **L2 - ReqToTokenPool (å¯»å€å±‚)**: ç±»ä¼¼ OS é¡µè¡¨çš„åœ°å€æ˜ å°„
   - **L3 - TokenToKVPool (ç‰©ç†å±‚)**: GPU æ˜¾å­˜ä¸­çš„å®é™… KV Tensor

2. **PagedAttention vs RadixCache**
   - **PagedAttention**: è§£å†³æ˜¾å­˜ç¢ç‰‡é—®é¢˜ï¼ˆç±»ä¼¼ OS é¡µè¡¨ï¼‰
   - **RadixCache**: è§£å†³é‡å¤è®¡ç®—é—®é¢˜ï¼ˆç±»ä¼¼æ–‡ä»¶ç¼“å­˜ï¼‰
   - ä¸¤è€…äº’è¡¥ï¼Œä¸çŸ›ç›¾

3. **Zero Overhead Scheduling**
   - **ç›®æ ‡**: å°† CPU è°ƒåº¦å¼€é”€éšè—åœ¨ GPU è®¡ç®—ä¸­
   - **æ–¹æ³•**: FutureMap æœºåˆ¶å®ç° CPU-GPU é‡å 
   - **æ•ˆæœ**: æ¥è¿‘é›¶è°ƒåº¦å¼€é”€

### æŠ€æœ¯è¦ç‚¹

#### å…³é”®æ•°æ®ç»“æ„

**1. Scheduler çŠ¶æ€ç®¡ç†**:
```
waiting_queue   â†’ ä¼˜å…ˆé˜Ÿåˆ—ï¼Œå¾…å¤„ç†çš„è¯·æ±‚
new_batch       â†’ å³å°†è¿›å…¥ prefill çš„è¯·æ±‚
running_batch   â†’ å³å°†è¿›å…¥ decode çš„è¯·æ±‚
cur_batch       â†’ å½“å‰æ­£åœ¨å¤„ç†çš„è¯·æ±‚
```

**è°ƒåº¦è½¨è¿¹**:
- æ–°è¯·æ±‚: `waiting_queue â†’ new_batch â†’ last_batch â†’ running_batch`
- Decode è¯·æ±‚: `running_batch â†’ cur_batch â†’ running_batch`

**2. å››ç§ Batch ç±»å‹**:
- `ScheduleBatch`: Scheduler ç®¡ç†çš„é«˜çº§è°ƒåº¦ä¿¡æ¯ï¼ˆCPUï¼‰
- `ModelWorkerBatch`: GPU æ¨¡å‹ forward ç›¸å…³æ•°æ®
- `ForwardBatch`: æœ€åº•å±‚çš„ tensor æ•°æ®ï¼ˆGPUï¼‰
- `GenerationBatchResult`: æ¨¡å‹ forward çš„è¾“å‡ºç»“æœ

**3. RadixCache (L1 Cache)**
```python
class TreeNode:
    key = token_ids          # é€»è¾‘æ ‡è¯†ï¼šToken åºåˆ—
    value = slot_indices     # ç‰©ç†ç´¢å¼•ï¼šKV Cache æ§½ä½
    lock_ref = 0             # å¼•ç”¨è®¡æ•°
    children = {}            # å­èŠ‚ç‚¹åˆ†æ”¯
    last_access_time         # LRU æ—¶é—´æˆ³
```

**æ ¸å¿ƒåŠŸèƒ½**:
- `match_prefix`: æœç´¢æœ€é•¿å‰ç¼€
- `evict`: é‡Šæ”¾å†·å‰ç¼€
- å¼•ç”¨è®¡æ•°ç®¡ç†

**4. ReqToTokenPool (L2 Cache)**
```python
# äºŒç»´çŸ©é˜µï¼š[è¯·æ±‚æ•°é‡, æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦]
req_to_token[req_id][pos] = physical_slot_index
```

**ä½œç”¨**: ç±»ä¼¼ OS é¡µè¡¨ï¼Œå°†é€»è¾‘åœ°å€æ˜ å°„åˆ°ç‰©ç†åœ°å€

**5. TokenToKVPool (L3 Cache)**
- GPU æ˜¾å­˜ä¸­çš„å®é™… KV Tensor
- ç‰©ç†æ§½ä½ä¸éœ€è¦è¿ç»­
- é€šè¿‡ Paged Attention é€»è¾‘ä¸Š"ç¼åˆ"

#### Normal Scheduler å·¥ä½œæµ

**äº‹ä»¶å¾ªç¯**:
```python
while True:
    # 1. Pre Schedule (CPU)
    recv_requests()
    batch = get_next_batch_to_run()

    # 2. Compute Batch & Sample (GPU)
    result = run_batch(batch)

    # 3. Post Schedule (CPU)
    process_batch_result(batch, result)
```

**å››ä¸ªé˜¶æ®µ**:
| äº‹ä»¶ | è®¡ç®—ä½ç½® | ç‰¹ç‚¹ |
|------|---------|------|
| Pre Schedule | CPU Heavy | å‡†å¤‡è¾“å…¥ã€åˆ†é…ç¼“å­˜ |
| Compute Batch | GPU Heavy | æ¨¡å‹å‰å‘è®¡ç®— |
| Sample | GPU Heavy | åœ¨ GPU ä¸Šé‡‡æ ·ï¼ˆé¿å…ä¼ è¾“ logitsï¼‰ |
| Post Schedule | CPU Heavy | æ›´æ–°çŠ¶æ€ã€æµå¼è¾“å‡º |

**ä¸ºä»€ä¹ˆåœ¨ GPU ä¸Šé‡‡æ ·**ï¼Ÿ
- Logits å¤§å°: 256 Ã— 128,000 Ã— 2 bytes â‰ˆ **65 MB**
- ä¼ è¾“åˆ° CPU é‡‡æ ·: PCIe å¼€é”€å·¨å¤§
- åœ¨ GPU é‡‡æ ·: åªä¼ å› Token IDs (< 1 KB)

#### Zero Overhead Scheduling

**æ ¸å¿ƒæ€æƒ³**: CPU-GPU é‡å æ‰§è¡Œ

**FutureMap æœºåˆ¶**:
1. **CPU ä¾§ - ç¬¦å·åŒ–é“¾æ¥**:
   - é¢„å…ˆåœ¨ FutureMap ä¸­é¢„ç•™æ§½ä½
   - é€šè¿‡ç¬¦å·å¼•ç”¨å®Œæˆ Batch N â†’ N+1 çš„æ‹“æ‰‘é“¾æ¥
   - ä¸éœ€è¦çœŸå®æ•°æ®å°±èƒ½å‡†å¤‡ä¸‹ä¸€è½®è¾“å…¥

2. **GPU ä¾§ - å»¶è¿Ÿè§£æ**:
   - Batch N+1 å¯åŠ¨å‰å…ˆè¿è¡Œ Resolve Kernel
   - ä» FutureMap è¯»å–çœŸå® Token ID
   - åŸåœ°æ›¿æ¢è¾“å…¥å¼ é‡

**Overlap æ•ˆæœ**:
```
æ—¶é—´çº¿:
CPU: Post N  | Pre N+1   | Post N+1 |
GPU: Compute N+1 | Sample N+1 |
      â†‘ é‡å  â†‘
```

**å…³é”®**: CPU å’Œ GPU å®Œå…¨å¹¶è¡Œï¼Œæ— ç­‰å¾…

### é‡è¦å‘ç°

1. **Multi-step vs Overlap**
   - **Multi-step**: é™ä½è°ƒåº¦é¢‘ç‡ï¼ˆæ‘Šè–„å¼€é”€ï¼‰
     - ä¼˜ç‚¹: å‡å°‘è°ƒåº¦æ¬¡æ•°
     - ç¼ºç‚¹: EOS å“åº”æ»åã€å¤±å»çµæ´»æ€§

   - **Overlap**: ä¿æŒè°ƒåº¦é¢‘ç‡ï¼Œéšè—å¼€é”€
     - ä¼˜ç‚¹: çµæ´»æ€§ã€é›¶å¼€é”€
     - ç¼ºç‚¹: å®ç°å¤æ‚

2. **è°ƒåº¦çš„æ€§èƒ½ç“¶é¢ˆ**
   - ä¸æ˜¯è°ƒåº¦ç®—æ³•æœ¬èº«ï¼ˆå¾ˆå¿«ï¼‰
   - è€Œæ˜¯ Python ä¾§çš„ I/O å¤„ç†ï¼ˆå¾ˆæ…¢ï¼‰
   - è§£å†³æ–¹æ¡ˆ: å¼‚æ­¥æ©ç›–

3. **é‡‡æ ·ä½ç½®çš„é‡è¦æ€§**
   - åœ¨ GPU é‡‡æ ·é¿å…å¤§é‡æ•°æ®ä¼ è¾“
   - Logits (65 MB) vs Token IDs (< 1 KB)
   - æ¯è½®éƒ½è¦é‡‡æ ·ï¼Œä¼ è¾“å¼€é”€ä¼šç´¯ç§¯

4. **ä¸‰çº§ç¼“å­˜çš„ååŒ**
   - L1 (RadixCache): é€»è¾‘å±‚ï¼Œå‰ç¼€å¤ç”¨
   - L2 (ReqToTokenPool): å¯»å€å±‚ï¼Œé¡µè¡¨æ˜ å°„
   - L3 (TokenToKVPool): ç‰©ç†å±‚ï¼Œå®é™…å­˜å‚¨
   - ç±»ä¼¼ OS çš„å¤šçº§ç´¢å¼•

---

## ğŸ’¡ ä¸ªäººæ€è€ƒ

### æœ‰å¯å‘çš„ç‚¹

1. **OS ç±»æ¯”çš„æ·±åº¦**
   - PagedAttention â‰ˆ é¡µè¡¨
   - RadixCache â‰ˆ æ–‡ä»¶ç¼“å­˜
   - ReqToTokenPool â‰ˆ é¡µè¡¨é¡¹
   - è¿™ä¸ªç±»æ¯”è®©ç†è§£å˜å¾—ç›´è§‚

2. **ç¬¦å·åŒ–é“¾æ¥çš„å·§å¦™**
   - CPU ä¸çŸ¥é“çœŸå® Token ID å°±èƒ½å‡†å¤‡ä¸‹ä¸€è½®
   - é€šè¿‡å¼•ç”¨è€Œéæ•°å€¼æ¥å»ºç«‹è¿æ¥
   - ç±»ä¼¼äºç¬¦å·é“¾æ¥ vs ç¡¬é“¾æ¥

3. **é‡‡æ ·åœ¨ GPU çš„æ´å¯Ÿ**
   - 65 MB vs 1 KB çš„æ•°æ®ä¼ è¾“å¯¹æ¯”
   - è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„æ—¶é—´æ¢ç©ºé—´ï¼ˆæˆ–ç©ºé—´æ¢æ—¶é—´ï¼‰çš„æƒè¡¡
   - åœ¨å…³é”®è·¯å¾„ä¸Šå‡å°‘æ•°æ®ä¼ è¾“è‡³å…³é‡è¦

4. **Overlap èƒœè¿‡ Multi-step**
   - Multi-step: ç”¨çµæ´»æ€§æ¢æ•ˆç‡
   - Overlap: ä¿æŒçµæ´»æ€§ï¼Œé€šè¿‡å¹¶å‘æå‡æ•ˆç‡
   - Overlap æ˜¯æ›´ä¼˜çš„è§£

### ç–‘é—®

1. **FutureMap çš„å®ç°ç»†èŠ‚**
   - å¦‚ä½•é¢„ç•™æ§½ä½ï¼Ÿ
   - å¦‚ä½•å¤„ç†é¢„ç•™å¤±è´¥ï¼Ÿ
   - å¦‚ä½•ç®¡ç†æ§½ä½çš„ç”Ÿå‘½å‘¨æœŸï¼Ÿ

2. **é”™è¯¯å¤„ç†**
   - å¦‚æœ GPU è®¡ç®—å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
   - FutureMap ä¸­çš„ç¬¦å·å¼•ç”¨å¦‚ä½•å¤±æ•ˆï¼Ÿ
   - å¦‚ä½•å›æ»šå·²ç»å‘å°„çš„æŒ‡ä»¤ï¼Ÿ

3. **å†…å­˜ç®¡ç†**
   - RadixCache çš„é©±é€ç­–ç•¥ç»†èŠ‚
   - å¦‚ä½•å¹³è¡¡å…±äº«å’Œç§æœ‰å†…å­˜ï¼Ÿ
   - å¦‚ä½•é¿å…å†…å­˜æ³„æ¼ï¼Ÿ

4. **ä¸ vLLM çš„å¯¹æ¯”**
   - SGLang vs vLLM çš„æ€§èƒ½å·®å¼‚
   - å„è‡ªçš„ä¼˜ç¼ºç‚¹
   - é€‚ç”¨åœºæ™¯

### ä¸å…¶ä»–æ–‡ç« çš„å…³è”

- **GLM4-MoE ä¼˜åŒ– (BLOG_001)**:
  - éƒ½å…³æ³¨æ¨ç†ç³»ç»Ÿä¼˜åŒ–
  - GLM4: MoE ç‰¹å®šä¼˜åŒ–
  - SGLang: é€šç”¨è°ƒåº¦ä¼˜åŒ–
  - å¯ä»¥ç»“åˆä½¿ç”¨

- **TATER (PAPER_001)**:
  - TATER: æµ‹è¯•æ—¶æœç´¢ç»éªŒå›æ”¶
  - SGLang: è°ƒåº¦å’Œç¼“å­˜ä¼˜åŒ–
  - éƒ½åœ¨ä¼˜åŒ–æ¨ç†æ•ˆç‡

- **Fast-ThinkAct (AGENT_002)**:
  - Fast-ThinkAct: æ¨ç†è¡¨ç¤ºå‹ç¼©
  - SGLang: ç³»ç»Ÿçº§è°ƒåº¦ä¼˜åŒ–
  - ä¸åŒå±‚é¢çš„æ•ˆç‡æå‡

---

## ğŸ“ å…³é”®æ‘˜å½•

> "RL infra çš„ä¸Šé™ï¼Œå…¶å®å–å†³äºå¯¹ SGLang å’Œ Megatron æœ¬èº«çš„ç†è§£ç¨‹åº¦ã€‚"

> "PagedAttention ç±»ä¼¼æ“ä½œç³»ç»Ÿä¸­çš„é¡µè¡¨ï¼Œè§£å†³äº†é€»è¾‘ç¼“å­˜åœ°å€åˆ°ç‰©ç†å­˜å‚¨åœ°å€çš„æ˜ å°„é—®é¢˜ã€‚"

> "RadixCache è´Ÿè´£ç¼“å­˜å¤ç”¨çš„é—®é¢˜ï¼Œå‰ç¼€ç›¸åŒçš„ requests èƒ½å¤Ÿå¤ç”¨ä¸€è‡´çš„é€»è¾‘ç¼“å­˜åœ°å€ã€‚"

> "Overlap Scheduling é€šè¿‡ FutureMap æœºåˆ¶ï¼Œå°† CPU çš„è°ƒåº¦å¼€é”€å½»åº•éšè—åœ¨ GPU è®¡ç®—ä¹‹å†…ã€‚"

> "é‡‡æ ·å®è´¨ä¸Šå‘ç”Ÿåœ¨ GPU ä¸Šï¼Œé¿å…æ¯ä¸€è½®éƒ½ä¼ è¾“ 65 MB çš„ Logitsã€‚"

---

## ğŸ”— ç›¸å…³èµ„æº

- **åŸæ–‡**: https://zhuanlan.zhihu.com/p/1992587332189197731
- **æ•™ç¨‹ä»“åº“**: https://github.com/zhaochenyang20/Awesome-ML-Sys-Tutorial
- **ç›¸å…³é¡¹ç›®**:
  - SGLang: https://github.com/sgl-project/sglang
  - vLLM
- **ç›¸å…³æŠ€æœ¯**:
  - PagedAttention
  - RadixCache
  - KV Cache Management
  - CUDA Streams

---

## ğŸ“Š è¡¥å……è¯´æ˜

**SGLang è°ƒåº¦ç³»ç»Ÿçš„æ¼”è¿›**:

```
ç¬¬ä¸€é˜¶æ®µ: Normal Scheduler
  CPU å’Œ GPU ä¸²è¡Œæ‰§è¡Œ
  è°ƒåº¦å¼€é”€æ˜æ˜¾

ç¬¬äºŒé˜¶æ®µ: Multi-step Scheduling
  é™ä½è°ƒåº¦é¢‘ç‡
  æ‘Šè–„å¼€é”€ï¼Œå¤±å»çµæ´»æ€§

ç¬¬ä¸‰é˜¶æ®µ: Overlap Scheduling â­
  CPU-GPU å®Œå…¨å¹¶è¡Œ
  é›¶å¼€é”€è°ƒåº¦
```

**å…³é”®æŠ€æœ¯å¯¹æ¯”**:

| æŠ€æœ¯ | è§£å†³é—®é¢˜ | ç±»æ¯” |
|------|---------|------|
| **PagedAttention** | æ˜¾å­˜ç¢ç‰‡ | OS é¡µè¡¨ |
| **RadixCache** | é‡å¤è®¡ç®— | æ–‡ä»¶ç¼“å­˜ |
| **FutureMap** | CPU-GPU ä¾èµ– | ç¬¦å·é“¾æ¥ |

**Zero Overhead çš„å®ç°åŸç†**:

**ä¼ ç»Ÿæ–¹æ³•**ï¼ˆä¸²è¡Œï¼‰:
```
Step 1: CPU å‡†å¤‡ Batch N
Step 2: GPU è®¡ç®— Batch N
Step 3: GPU é‡‡æ ·
Step 4: CPU å¤„ç†ç»“æœ
Step 5: CPU å‡†å¤‡ Batch N+1
...
æ€»æ—¶é—´ = CPU + GPU + CPU + GPU + ...
```

**Overlap æ–¹æ³•**ï¼ˆå¹¶è¡Œï¼‰:
```
æ—¶é—´è½´ â†’
CPU:  [Post N] [Pre N+1] [Post N+1]
GPU:     [Compute N+1] [Sample N+1]
         â†‘ å¹¶è¡Œæ‰§è¡Œ â†‘
æ€»æ—¶é—´ â‰ˆ max(CPU, GPU)
```

**æ ¸å¿ƒæœºåˆ¶ - FutureMap**:

```python
# ä¼ªä»£ç 
class FutureMap:
    def __init__(self):
        self.slots = {}  # slot_id â†’ value

    # CPU ä¾§: é¢„ç•™æ§½ä½
    def reserve(self, slot_id):
        self.slots[slot_id] = None  # å ä½

    # CPU ä¾§: ç¬¦å·å¼•ç”¨
    def get_symbolic_ref(self, slot_id):
        return f"future[{slot_id}]"  # è¿”å›ç¬¦å·

    # GPU ä¾§: å»¶è¿Ÿè§£æ
    def resolve(self, slot_id):
        return self.slots[slot_id]  # è¿”å›çœŸå®å€¼
```

**ä½¿ç”¨æµç¨‹**:
```python
# Batch N æ­£åœ¨è®¡ç®—
# CPU æå‰å‡†å¤‡ Batch N+1
future_slot = future_map.reserve(42)
input_tensor[N+1] = future_map.get_symbolic_ref(42)

# GPU è®¡ç®— Batch N å®Œæˆ
# é‡‡æ ·ç»“æœå†™å…¥ FutureMap
future_map.slots[42] = actual_token_id

# GPU å¼€å§‹è®¡ç®— Batch N+1
# Resolve Kernel æ›¿æ¢ç¬¦å·å¼•ç”¨
resolve_kernel(input_tensor[N+1], future_map)
```

**æ€§èƒ½åˆ†æ**:

**Normal Scheduler å¼€é”€**:
- CPU è°ƒåº¦: ~1-2 ms (Python å¤„ç†)
- GPU è®¡ç®—: ~10-20 ms (å•æ­¥ decode)
- è°ƒåº¦å¼€é”€å æ¯”: 5-20%

**Overlap Scheduler å¼€é”€**:
- CPU è°ƒåº¦: éšè—åœ¨ GPU è®¡ç®—ä¸­
- GPU è®¡ç®—: ~10-20 ms (å•æ­¥ decode)
- **è°ƒåº¦å¼€é”€å æ¯”: â‰ˆ 0%** âœ…

**å®è·µå»ºè®®**:

1. **ç†è§£ç“¶é¢ˆ**
   - ä¸æ˜¯è°ƒåº¦ç®—æ³•æ…¢
   - è€Œæ˜¯ Python I/O å¤„ç†æ…¢
   - é‡ç‚¹ä¼˜åŒ– Python ä¾§

2. **é€‰æ‹©ç­–ç•¥**
   - é«˜åååœºæ™¯: Multi-step æˆ– Overlap
   - ä½å»¶è¿Ÿåœºæ™¯: Overlap
   - èµ„æºå—é™: Multi-step

3. **ç›‘æ§æŒ‡æ ‡**
   - CPU åˆ©ç”¨ç‡
   - GPU åˆ©ç”¨ç‡
   - è°ƒåº¦å»¶è¿Ÿ
   - ç«¯åˆ°ç«¯å»¶è¿Ÿ

**ç³»ç»Ÿè®¾è®¡çš„å¯ç¤º**:

1. **åˆ†å±‚æŠ½è±¡**
   - L1/L2/L3 ç¼“å­˜å±‚æ¬¡åˆ†æ˜
   - æ¯å±‚è§£å†³ä¸åŒé—®é¢˜
   - ä¼˜é›…çš„èŒè´£åˆ†ç¦»

2. **ç¬¦å·åŒ–è®¾è®¡**
   - FutureMap çš„ç¬¦å·å¼•ç”¨
   - è§£è€¦æ—¶é—´å’Œç©ºé—´
   - å®ç°å¼‚æ­¥å¹¶è¡Œ

3. **æƒè¡¡å–èˆ**
   - Multi-step: ç®€å•ä½†ä¸çµæ´»
   - Overlap: å¤æ‚ä½†é«˜æ•ˆ
   - æ ¹æ®åœºæ™¯é€‰æ‹©

**æœªæ¥æ–¹å‘**:

1. æ›´æ™ºèƒ½çš„è°ƒåº¦ç­–ç•¥
2. è‡ªé€‚åº”çš„ç¼“å­˜ç®¡ç†
3. æ›´å¥½çš„æ˜¾å­˜åˆ©ç”¨ç‡
4. æ”¯æŒæ›´å¤šæ¨¡å‹æ¶æ„
5. é™ä½å®ç°å¤æ‚åº¦

**æ ¸å¿ƒæ´å¯Ÿ**:

è¿™ç¯‡æ–‡ç« çš„æ ¸å¿ƒæ´å¯Ÿæ˜¯ï¼š**ç³»ç»Ÿä¼˜åŒ–çš„ä¸Šé™åœ¨äºå¯¹åº•å±‚æœºåˆ¶çš„æ·±åˆ»ç†è§£**ã€‚

RL infra çš„ä¸Šé™ä¸åªæ˜¯ç®—æ³•ï¼Œè¿˜åŒ…æ‹¬ï¼š
- å¯¹è°ƒåº¦å™¨çš„ç†è§£
- å¯¹ KV Cache çš„ç†è§£
- å¯¹ GPU æ‰§è¡Œæ¨¡å‹çš„ç†è§£

æ­£å¦‚ä½œè€…æ‰€è¯´ï¼š
> "å¾ˆå¤šæ—¶å€™ RL infra çš„ä¸Šé™ï¼Œå…¶å®å–å†³äºå¯¹ SGLang å’Œ Megatron æœ¬èº«çš„ç†è§£ç¨‹åº¦ã€‚"

è¿™æé†’æˆ‘ä»¬ï¼š
- ä¸è¦åªå…³æ³¨ç®—æ³•å±‚é¢
- ç³»ç»Ÿå±‚é¢çš„ä¼˜åŒ–åŒæ ·é‡è¦
- æ·±å…¥ç†è§£åº•å±‚æ‰èƒ½çªç ´ä¸Šé™

Zero Overhead Scheduling æ˜¯ä¸€ä¸ªæ¼‚äº®çš„ä¾‹å­ï¼š
- é€šè¿‡æ·±åˆ»çš„ç³»ç»Ÿç†è§£
- å·§å¦™çš„ç¬¦å·åŒ–è®¾è®¡
- å®ç°äº†çœ‹ä¼¼ä¸å¯èƒ½çš„ç›®æ ‡

è¿™æ˜¯ä¸€ç¯‡éå¸¸å®ç”¨çš„æŠ€æœ¯æ–‡ç« ï¼Œå€¼å¾—åå¤é˜…è¯»å’Œå®è·µï¼
